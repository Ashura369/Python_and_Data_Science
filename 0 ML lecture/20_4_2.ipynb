{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc9626f",
   "metadata": {},
   "source": [
    "There is an inbuilt function for using SGDRegressor. There is no need to always making a class and then using it. See the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecceaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1389ea1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X,y = load_diabetes(return_X_y=True)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape, '\\n')\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633696bc",
   "metadata": {},
   "source": [
    "REMEMBER : before using SGDRegressor you have to scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac190909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4439830633089791\n"
     ]
    }
   ],
   "source": [
    "# SGD is very sensitive to feature scaling. If you don't scale, it won't converge.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initializing the model\n",
    "# max_iter=25: Maximum number of epochs (passes over the data)\n",
    "# eta0=0.1: Initial learning rate\n",
    "model = SGDRegressor(max_iter=25, eta0=0.01, random_state=42)\n",
    "\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b9552c",
   "metadata": {},
   "source": [
    "### Parameters of `SGDRegressor()` Explained Simply\n",
    "#### 1. The Strategy (Loss & Penalty)\n",
    "*   **`loss`**: **\"How do we measure mistakes?\"**\n",
    "    *   `'squared_error'`: The standard way. Good for normal data.\n",
    "    *   `'huber'`: The tough way. Use this if your data has \"crazy\" outliers (extreme values) so they don't mess up the model.\n",
    "*   **`penalty`**: **\"The restriction rules.\"** Helps prevent the model from memorizing the data (overfitting).\n",
    "    *   `'l2'`: Default rule. Keeps numbers small (Ridge).\n",
    "    *   `'l1'`: Strict rule. Can force unimportant features to zero (Lasso).\n",
    "    *   `'elasticnet'`: A mix of both rules.\n",
    "*   **`alpha`**: **\"How strict is the penalty?\"**\n",
    "    *   Higher number = Stricter rules (simpler model). [may cause overfitting]\n",
    "    *   Lower number = More freedom. [may cause underfitting]\n",
    "*   **`l1_ratio`**: **\"The Mix.\"** Only used if you chose `'elasticnet'`.\n",
    "    *   `0` = All L2. `1` = All L1. `0.5` = Half and Half.\n",
    "#### 2. The Learning Process\n",
    "*   **`max_iter`**: **\"Max Practice Runs.\"** The absolute maximum number of times the model will look at your data training loop (epochs).\n",
    "*   **`tol`**: **\"Good Enough Line.\"** If the model stops improving by at least this amount, it stops training early to save time.\n",
    "*   **`shuffle`**: **\"Shuffle the Deck.\"** If `True`, it mixes up the data rows before every practice run. (Usually a good idea).\n",
    "*   **`random_state`**: **\"The Replay Key.\"** Pick a number (like `42`) to make sure \"random\" things happen the exact same way every time you run the code.\n",
    "#### 3. The Speed (Learning Rate)\n",
    "*   **`learning_rate`**: **\"How fast do we adjust?\"**\n",
    "    *   `'constant'`: Same speed forever.\n",
    "    *   `'optimal'`: The \"smart\" default. Starts fast, slows down automatically.\n",
    "    *   `'adaptive'`: Keeps going at the same speed until it gets stuck, then slows down to find the perfect spot.\n",
    "*   **`eta0`**: **\"Starting Speed.\"** The initial step size the model takes.\n",
    "#### 4. When to Stop (Early Stopping)\n",
    "*   **`early_stopping`**: **\"The Safety Brake.\"** If `True`, the model sets aside some data to test itself. If it stops getting better on that test data, it quits training immediately.\n",
    "*   **`validation_fraction`**: **\"Test Size.\"** What percent of data to set aside for the safety brake (e.g., `0.1` is 10%).\n",
    "*   **`n_iter_no_change`**: **\"Patience.\"** How many times in a row can the model fail to improve before we actually pull the safety brake?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
