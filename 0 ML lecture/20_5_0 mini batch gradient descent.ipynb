{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89722ab",
   "metadata": {},
   "source": [
    "# **Mini Batch Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b538146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c66711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,) \n",
      "\n",
      "\n",
      "[  -9.15865318 -205.45432163  516.69374454  340.61999905 -895.5520019\n",
      "  561.22067904  153.89310954  126.73139688  861.12700152   52.42112238]\n",
      "\n",
      "151.88331005254167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X,y = load_diabetes(return_X_y=True)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape, '\\n')\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print()\n",
    "print(reg.coef_)\n",
    "print()\n",
    "print(reg.intercept_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553476ba",
   "metadata": {},
   "source": [
    "## **Type 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14935795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n",
      "10\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[1 2 3 4 5 6 7 8 9]\n",
      "[1 3 5 7 9]\n",
      "30\n",
      "\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[11 12 13 14 15 16 17 18 19 20]\n",
      "935\n",
      "[ 11  24  39  56  75  96 119 144 171 200]\n",
      "935\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "print(X_train.shape[1])\n",
    "print(np.arange(10))\n",
    "print(np.arange(1, 10))\n",
    "print(np.arange(1, 10, 2))\n",
    "print(np.dot(10,3))\n",
    "\n",
    "\n",
    "a = np.array(np.arange(1,11))\n",
    "b = np.array(np.arange(11,21))\n",
    "print()\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.dot(a,b))\n",
    "print(a*b)\n",
    "print(sum(a*b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feaae354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MBGDRegressor:\n",
    "    def __init__(self, batch_size, learning_rate=0.01, epochs=100):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        m = X_train.shape[0]  # Number of rows\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            # Shuffle the data at the start of each epoch\n",
    "            # This ensures batches are random but cover all data\n",
    "            indices = np.arange(m)\n",
    "            np.random.shuffle(indices)\n",
    "            X_shuffled = X_train[indices]\n",
    "            y_shuffled = y_train[indices]\n",
    "            \n",
    "            # Loop through batches\n",
    "            for j in range(0, m, self.batch_size):\n",
    "                \n",
    "                # Creating the Batch\n",
    "                X_batch = X_shuffled[j : j + self.batch_size]\n",
    "                y_batch = y_shuffled[j : j + self.batch_size]\n",
    "                \n",
    "                # mx + b\n",
    "                y_hat = np.dot(X_batch, self.coef_) + self.intercept_\n",
    "\n",
    "                # error = y - y_hat\n",
    "                error = y_batch - y_hat\n",
    "                \n",
    "                intercept_der = -2 * np.mean(error)\n",
    "                \n",
    "                coef_der = -2 * np.dot(X_batch.T, error) / X_batch.shape[0]\n",
    "                \n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(\"Intercept:\", self.intercept_)\n",
    "        print(\"Coefs:\", self.coef_)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return np.dot(X_test, self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34143d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 150.61523531440818\n",
      "Coefs: [ 42.11192634   2.76500316 128.21371529  97.49399045  35.56480679\n",
      "  24.06830272 -76.01798806  76.58061608 123.50963287  70.62740726]\n",
      "\n",
      "ACCURACY :  0.2709687070257346\n"
     ]
    }
   ],
   "source": [
    "reg = MBGDRegressor(10)\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print('\\nACCURACY : ', r2_score(y_test, y_pred))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe7f605",
   "metadata": {},
   "source": [
    "### **Understanding Batch Slicing Logic**\n",
    "The line `X_batch = X_shuffled[j : j + self.batch_size]` uses Python slicing to grab specific chunks of data.\n",
    "**Example Scenario:**\n",
    "- Total Rows (`m`) = **100**\n",
    "- Batch Size (`batch_size`) = **10**\n",
    "- Loop: `range(0, 100, 10)` $\\rightarrow$ `j` takes values `0, 10, 20...`\n",
    "---\n",
    "#### **Iteration 1 ($j=0$)**\n",
    "- **Start Index:** $0$\n",
    "- **End Index:** $0 + 10 = 10$\n",
    "- **Code:** `X_shuffled[0 : 10]`\n",
    "- **Action:** Grabs rows **0 to 9** (First 10 rows).\n",
    "#### **Iteration 2 ($j=10$)**\n",
    "- **Start Index:** $10$\n",
    "- **End Index:** $10 + 10 = 20$\n",
    "- **Code:** `X_shuffled[10 : 20]`\n",
    "- **Action:** Grabs rows **10 to 19** (Next 10 rows).\n",
    "#### **Iteration 3 ($j=20$)**\n",
    "- **Start Index:** $20$\n",
    "- **End Index:** $20 + 10 = 30$\n",
    "- **Code:** `X_shuffled[20 : 30]`\n",
    "- **Action:** Grabs rows **20 to 29**.\n",
    "---\n",
    "This process repeats until the entire dataset has been processed in chunks of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0f420",
   "metadata": {},
   "source": [
    "## **Type 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aae19148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Intercept: [147.5832478]\n",
      "Final Coefficients: [  50.1616004   -71.63788668  351.35743363  245.71158932   19.41568848\n",
      "  -24.91945094 -174.2600333   130.28248919  316.73524097  124.75413176] \n",
      "\n",
      "0.43097349182018674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = SGDRegressor(learning_rate='constant', eta0=0.1, random_state=42)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    X_shuffled, y_shuffled = shuffle(X_train, y_train, random_state=epoch)\n",
    "    \n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        \n",
    "        X_batch = X_shuffled[i : i+batch_size]\n",
    "        y_batch = y_shuffled[i : i+batch_size]\n",
    "        \n",
    "        # KEY PART: Use partial_fit() instead of fit()\n",
    "        # partial_fit updates weights based on the current batch without forgetting previous learning\n",
    "        # keeps the memory of what it learned before\n",
    "        # .fit() would reset weights to random numbers every time you call it\n",
    "        model.partial_fit(X_batch, y_batch)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Final Intercept:\", model.intercept_)\n",
    "print(\"Final Coefficients:\", model.coef_, '\\n')\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(r2_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fafa5f",
   "metadata": {},
   "source": [
    "- fit(): Loads ALL data into memory and runs the algorithm.\n",
    "- partial_fit(): Designed for \"Online Learning\" or \"Out-of-Core Learning\". It takes a small chunk, updates the weights, and discards the chunk from memory. This is exactly what Mini-Batch Gradient Descent is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
