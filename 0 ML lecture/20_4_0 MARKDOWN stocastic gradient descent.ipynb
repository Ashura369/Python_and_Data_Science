{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836a7e78",
   "metadata": {},
   "source": [
    "# **Stocastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b67bbc",
   "metadata": {},
   "source": [
    "**(most used)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3528553",
   "metadata": {},
   "source": [
    "\n",
    "### **1. The Dataset**\n",
    "We are predicting a Test Score based on three inputs.\n",
    "| Row | Study Hours ($x_1$) | Attendance ($x_2$) | Prior Grade ($x_3$) | Actual Score ($y$) |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "| **1** | 10 | 0.8 | 70 | **75** |\n",
    "| **2** | 5 | 0.9 | 80 | **82** |\n",
    "\n",
    "\n",
    "2. Initial Parameters\n",
    "\n",
    "We initialize our model with starting weights and a learning rate ($\\alpha$).\n",
    "- Weights ($w$): $m_1 = 1.0, \\quad m_2 = 1.0, \\quad m_3 = 1.0$\n",
    "- Intercept ($b$): $0.0$\n",
    "\n",
    "Learning Rate ($\\alpha$): $0.01$\n",
    "\n",
    "3. Iteration 1: Using Row 1\n",
    "\n",
    "Data point: $\\{x_1=10, x_2=0.8, x_3=70, y=75\\}$\n",
    "\n",
    "A. Prediction ($\\hat{y}$)\n",
    "\n",
    "$$\\hat{y} = (m_1 \\cdot x_1) + (m_2 \\cdot x_2) + (m_3 \\cdot x_3) + b$$\n",
    "\n",
    "$$\\hat{y} = (1.0 \\cdot 10) + (1.0 \\cdot 0.8) + (1.0 \\cdot 70) + 0$$\n",
    "\n",
    "$$\\hat{y} = 10 + 0.8 + 70 = \\mathbf{80.8}$$\n",
    "\n",
    "B. Calculate Error\n",
    "\n",
    "$$\\text{Error} = \\hat{y} - y = 80.8 - 75 = \\mathbf{5.8}$$\n",
    "\n",
    "C. Compute Gradient\n",
    "\n",
    "For a single row, the gradient is: *$\\text{Grad} = 2 \\cdot \\text{Error} \\cdot \\text{Feature}$*\n",
    "\n",
    "Intercept ($b$): $2 \\cdot 5.8 = \\mathbf{11.6}$\n",
    "- $m_1$ (Study): $2 \\cdot 5.8 \\cdot 10 = \\mathbf{116.0}$\n",
    "- $m_2$ (Attend): $2 \\cdot 5.8 \\cdot 0.8 = \\mathbf{9.28}$\n",
    "- $m_3$ (Grade): $2 \\cdot 5.8 \\cdot 70 = \\mathbf{812.0}$\n",
    "\n",
    "D. Update Parameters (Immediate Update)\n",
    "\n",
    "$$\\text{New} = \\text{Old} - (\\alpha \\cdot \\text{Gradient})$$\n",
    "\n",
    "- $b_{new} = 0.0 - (0.01 \\cdot 11.6) = \\mathbf{-0.116}$\n",
    "- $m_{1,new} = 1.0 - (0.01 \\cdot 116.0) = \\mathbf{-0.16}$\n",
    "- $m_{2,new} = 1.0 - (0.01 \\cdot 9.28) = \\mathbf{0.907}$\n",
    "- $m_{3,new} = 1.0 - (0.01 \\cdot 812.0) = \\mathbf{-7.12}$\n",
    "\n",
    "4. Iteration 2: Using Row 2\n",
    "\n",
    "Data point: $\\{x_1=5, x_2=0.9, x_3=80, y=82\\}$\n",
    "\n",
    "Note: We use the updated weights from Iteration 1.\n",
    "\n",
    "A. Prediction ($\\hat{y}$)\n",
    "\n",
    "$$\\hat{y} = (-0.16 \\cdot 5) + (0.907 \\cdot 0.9) + (-7.12 \\cdot 80) + (-0.116)$$\n",
    "$$\\hat{y} = (-0.8) + (0.816) + (-569.6) - 0.116 = \\mathbf{-569.7}$$\n",
    "\n",
    "B. Calculate Error\n",
    "\n",
    "$$\\text{Error} = \\hat{y} - y = -569.7 - 82 = \\mathbf{-651.7}$$\n",
    "\n",
    "C. Compute Gradient\n",
    "\n",
    "Intercept ($b$): $2 \\cdot -651.7 = \\mathbf{-1303.4}$\n",
    "\n",
    "- $m_1$ (Study): $2 \\cdot -651.7 \\cdot 5 = \\mathbf{-6517.0}$\n",
    "- $m_2$ (Attend): $2 \\cdot -651.7 \\cdot 0.9 = \\mathbf{-1173.06}$\n",
    "- $m_3$ (Grade): $2 \\cdot -651.7 \\cdot 80 = \\mathbf{-104272.0}$\n",
    "\n",
    "D. Update Parameters\n",
    "\n",
    "- $b_{final} = -0.116 - (0.01 \\cdot -1303.4) = \\mathbf{12.91}$\n",
    "- $m_{1,final} = -0.16 - (0.01 \\cdot -6517.0) = \\mathbf{65.01}$\n",
    "- $m_{2,final} = 0.907 - (0.01 \\cdot -1173.06) = \\mathbf{12.63}$\n",
    "- $m_{3,final} = -7.12 - (0.01 \\cdot -104272.0) = \\mathbf{1035.6}$\n",
    "\n",
    "\n",
    "### **Summary of One Full Epoch**\n",
    "| Parameter | Start | After Row 1 | After Row 2 (Final) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Intercept ($b$)** | 0.0 | -0.116 | **12.91** |\n",
    "| **mx1** | 1.0 | -0.16 | **65.01** |\n",
    "| **mx2** | 1.0 | 0.907 | **12.63** |\n",
    "| **mx3** | 1.0 | -7.12 | **1035.6** |\n",
    "*Because the data is not scaled and the learning rate is relatively high (0.01), `SGD` fluctuates wildly row-to-row.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82b07a",
   "metadata": {},
   "source": [
    "$$\\text{Error} = -569.7 - 82 = \\mathbf{-651.7}$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
