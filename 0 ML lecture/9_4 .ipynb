{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2deb1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d44ed5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c4ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age               0\n",
      "Sex               0\n",
      "ChestPainType     0\n",
      "RestingBP         0\n",
      "Cholesterol       0\n",
      "FastingBS         0\n",
      "RestingECG        0\n",
      "MaxHR             0\n",
      "ExerciseAngina    0\n",
      "Oldpeak           0\n",
      "ST_Slope          0\n",
      "HeartDisease      0\n",
      "dtype: int64\n",
      "\n",
      "Age                50\n",
      "Sex                 2\n",
      "ChestPainType       4\n",
      "RestingBP          67\n",
      "Cholesterol       222\n",
      "FastingBS           2\n",
      "RestingECG          3\n",
      "MaxHR             119\n",
      "ExerciseAngina      2\n",
      "Oldpeak            53\n",
      "ST_Slope            3\n",
      "HeartDisease        2\n",
      "dtype: int64\n",
      "\n",
      "(918, 12)\n"
     ]
    }
   ],
   "source": [
    "# checking for null values\n",
    "print(f\"{df.isna().sum()}\\n\")\n",
    "\n",
    "# checking for unique values\n",
    "print(f\"{df.nunique()}\\n\")\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b46868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF x_train : (734, 14)\n",
      "ACCURACY SCORE : 84.0 %\n"
     ]
    }
   ],
   "source": [
    "# feature groups\n",
    "ohe = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina']\n",
    "oe = ['ST_Slope']\n",
    "stdScaler = ['Oldpeak', 'MaxHR', 'Cholesterol', 'RestingBP']            # scaling the numerical data\n",
    "\n",
    "# using column transformers\n",
    "trf = ColumnTransformer([\n",
    "    ('t1', OneHotEncoder(sparse_output=False, drop='first'), ohe),\n",
    "    ('t5', OrdinalEncoder(categories=[['Up', 'Flat', 'Down']]), oe),\n",
    "    ('t6', StandardScaler(), stdScaler)\n",
    "], remainder='passthrough')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " ---- WHAT IF oe WOULD HAVE HOLD MORE THAN ONE COLUMNS ---- \n",
    "\n",
    "\n",
    "oe = ['ST_Slope', 'AnotherCol', 'ThirdCol']\n",
    "\n",
    "trf = ColumnTransformer([\n",
    "    ('t1', OneHotEncoder(sparse_output=False, drop='first'), ohe),\n",
    "    ('t5', OrdinalEncoder(categories=[\n",
    "        ['Up', 'Flat', 'Down'],      # for ST_Slope\n",
    "        ['Low', 'Med', 'High'],      # for AnotherCol\n",
    "        ['Bad', 'Avg', 'Good']       # for ThirdCol\n",
    "    ]), oe),\n",
    "    ('t6', StandardScaler(), stdScaler)\n",
    "], remainder='passthrough')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns=['HeartDisease']), df['HeartDisease'], test_size=0.2, random_state=0)\n",
    "\n",
    "# copying x_train into another variable to store column names\n",
    "train_cols = x_train.copy()\n",
    "\n",
    "# encoding and scaling the data\n",
    "x_train = trf.fit_transform(x_train)\n",
    "x_test = trf.transform(x_test)\n",
    "print(f\"SHAPE OF x_train : {x_train.shape}\")\n",
    "\n",
    "\n",
    "# storing all the column names in a variable\n",
    "cols = (\n",
    "    list(trf.named_transformers_['t1'].get_feature_names_out(ohe))\n",
    "    + oe\n",
    "    + stdScaler\n",
    "    + [c for c in train_cols.columns if c not in (ohe + oe + stdScaler)]\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " ---- IMP ----\n",
    "\n",
    "You can only build `cols` after `trf.fit_transform()` because the transformers do not know the final output columns before fitting. \n",
    "OneHotEncoder and OrdinalEncoder create new columns based on learned categories. These new column names are only available after fit. \n",
    "So if you try to access `trf.named_transformers_` or `get_feature_names_out()` before fitting, it will fail. \n",
    "First fit → transformers learn categories → new columns exist → then you can build the final column list.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# convert back to DataFrame\n",
    "x_train = pd.DataFrame(x_train, columns=cols)\n",
    "x_test = pd.DataFrame(x_test, columns=cols)\n",
    "\n",
    "reg = LogisticRegression(max_iter=2000)     # just remove max_iter and you will see the difference\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "print(f\"ACCURACY SCORE : {np.round(accuracy_score(y_test, y_pred)*100)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96e7554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n ---- CAN I WRITE THIS ---- \\n cols = (\\n    list(trf.named_transformers_['t1'].get_feature_names_out(ohe))\\n    + list(trf.named_transformers_['t2'].get_feature_names_out(oe))\\n    + list(trf.named_transformers_['t3'].get_feature_names_out(stdScaler))\\n    + [c for c in train_cols.columns if c not in (ohe + oe + stdScaler)]\\n)\\n\\n\\nOneHotEncoder creates multiple new columns for each category. So \\nget_feature_names_out is useful because it returns the expanded column names.\\n\\nOrdinalEncoder does not create extra columns. It only replaces each category\\nwith an integer. Number of columns stays the same. So \\nget_feature_names_out returns the same original column names. That makes \\ncalling it unnecessary.\\n\\nStandardScaler also does not create or remove columns. It only scales \\nnumeric values. So its column names also stay the same.\\n\\nTherefore:\\n- Use get_feature_names_out only for OneHotEncoder.\\n- For OrdinalEncoder and StandardScaler, just reuse the original column names.\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " ---- CAN I WRITE THIS ---- \n",
    " cols = (\n",
    "    list(trf.named_transformers_['t1'].get_feature_names_out(ohe))\n",
    "    + list(trf.named_transformers_['t2'].get_feature_names_out(oe))\n",
    "    + list(trf.named_transformers_['t3'].get_feature_names_out(stdScaler))\n",
    "    + [c for c in train_cols.columns if c not in (ohe + oe + stdScaler)]\n",
    ")\n",
    "\n",
    "\n",
    "OneHotEncoder creates multiple new columns for each category. So \n",
    "get_feature_names_out is useful because it returns the expanded column names.\n",
    "\n",
    "OrdinalEncoder does not create extra columns. It only replaces each category\n",
    "with an integer. Number of columns stays the same. So \n",
    "get_feature_names_out returns the same original column names. That makes \n",
    "calling it unnecessary.\n",
    "\n",
    "StandardScaler also does not create or remove columns. It only scales \n",
    "numeric values. So its column names also stay the same.\n",
    "\n",
    "Therefore:\n",
    "- Use get_feature_names_out only for OneHotEncoder.\n",
    "- For OrdinalEncoder and StandardScaler, just reuse the original column names.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead18eb4",
   "metadata": {},
   "source": [
    "## Writing the same code again using Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5dc597",
   "metadata": {},
   "source": [
    "By using pipelines here we will realize how easier it becomes to write codes, rather than manually encoding and scaling every column through 'fit_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0e4794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY SCORE : 84.0 %\n"
     ]
    }
   ],
   "source": [
    "ohe = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina']\n",
    "oe = ['ST_Slope']\n",
    "stdScaler = ['Oldpeak', 'MaxHR', 'Cholesterol', 'RestingBP']\n",
    "\n",
    "# making a transformer\n",
    "trf = ColumnTransformer([\n",
    "    ('t1', OneHotEncoder(sparse_output=False, drop='first'), ohe),\n",
    "    ('t5', OrdinalEncoder(categories=[['Up', 'Flat', 'Down']]), oe),\n",
    "    ('t6', StandardScaler(), stdScaler)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# making a pipeline\n",
    "pipe = Pipeline([\n",
    "    ('trf', trf),\n",
    "    ('model', LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "# splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns=['HeartDisease']), df['HeartDisease'], test_size=0.2, random_state=0)\n",
    "\n",
    "# making prediction\n",
    "pipe.fit(x_train, y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "print(f\"ACCURACY SCORE : {np.round(accuracy_score(y_test, y_pred)*100)} %\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c42a69cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ExerciseAngina_Y</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Age</th>\n",
       "      <th>FastingBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.055374</td>\n",
       "      <td>0.793140</td>\n",
       "      <td>-1.850065</td>\n",
       "      <td>0.403985</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.577847</td>\n",
       "      <td>-0.924506</td>\n",
       "      <td>-1.850065</td>\n",
       "      <td>-0.950506</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.090691</td>\n",
       "      <td>0.558916</td>\n",
       "      <td>1.498941</td>\n",
       "      <td>1.487578</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100320</td>\n",
       "      <td>-1.666216</td>\n",
       "      <td>-0.556976</td>\n",
       "      <td>0.403985</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100320</td>\n",
       "      <td>-0.768356</td>\n",
       "      <td>-1.850065</td>\n",
       "      <td>0.403985</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.819417</td>\n",
       "      <td>-0.417019</td>\n",
       "      <td>0.373303</td>\n",
       "      <td>-1.221404</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.854734</td>\n",
       "      <td>0.910252</td>\n",
       "      <td>0.429120</td>\n",
       "      <td>-0.137811</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.854734</td>\n",
       "      <td>0.871215</td>\n",
       "      <td>0.968682</td>\n",
       "      <td>-0.246171</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.965482</td>\n",
       "      <td>-1.353917</td>\n",
       "      <td>0.689598</td>\n",
       "      <td>0.078907</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.854734</td>\n",
       "      <td>0.597953</td>\n",
       "      <td>0.410514</td>\n",
       "      <td>-1.329764</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_M  ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  \\\n",
       "0      1.0                0.0                0.0               0.0   \n",
       "1      1.0                0.0                0.0               0.0   \n",
       "2      0.0                0.0                1.0               0.0   \n",
       "3      1.0                0.0                0.0               0.0   \n",
       "4      1.0                0.0                0.0               0.0   \n",
       "..     ...                ...                ...               ...   \n",
       "729    1.0                0.0                0.0               0.0   \n",
       "730    1.0                1.0                0.0               0.0   \n",
       "731    0.0                0.0                0.0               0.0   \n",
       "732    1.0                0.0                0.0               0.0   \n",
       "733    1.0                0.0                1.0               0.0   \n",
       "\n",
       "     RestingECG_Normal  RestingECG_ST  ExerciseAngina_Y  ST_Slope   Oldpeak  \\\n",
       "0                  1.0            0.0               1.0       1.0  1.055374   \n",
       "1                  1.0            0.0               1.0       1.0  0.577847   \n",
       "2                  0.0            0.0               0.0       0.0 -0.090691   \n",
       "3                  1.0            0.0               1.0       1.0  0.100320   \n",
       "4                  0.0            1.0               1.0       1.0  0.100320   \n",
       "..                 ...            ...               ...       ...       ...   \n",
       "729                1.0            0.0               1.0       1.0  1.819417   \n",
       "730                1.0            0.0               0.0       0.0 -0.854734   \n",
       "731                0.0            0.0               0.0       0.0 -0.854734   \n",
       "732                1.0            0.0               1.0       2.0  2.965482   \n",
       "733                1.0            0.0               0.0       0.0 -0.854734   \n",
       "\n",
       "        MaxHR  Cholesterol  RestingBP   Age  FastingBS  \n",
       "0    0.793140    -1.850065   0.403985  70.0        1.0  \n",
       "1   -0.924506    -1.850065  -0.950506  46.0        0.0  \n",
       "2    0.558916     1.498941   1.487578  65.0        0.0  \n",
       "3   -1.666216    -0.556976   0.403985  66.0        0.0  \n",
       "4   -0.768356    -1.850065   0.403985  59.0        0.0  \n",
       "..        ...          ...        ...   ...        ...  \n",
       "729 -0.417019     0.373303  -1.221404  54.0        0.0  \n",
       "730  0.910252     0.429120  -0.137811  48.0        0.0  \n",
       "731  0.871215     0.968682  -0.246171  57.0        0.0  \n",
       "732 -1.353917     0.689598   0.078907  64.0        0.0  \n",
       "733  0.597953     0.410514  -1.329764  47.0        0.0  \n",
       "\n",
       "[734 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform x_train and x_test manually to get DataFrame with column names\n",
    "x_train_transformed = pipe.named_steps['trf'].transform(x_train)\n",
    "x_test_transformed = pipe.named_steps['trf'].transform(x_test)\n",
    "\n",
    "# get column names\n",
    "cols = list(pipe.named_steps['trf'].named_transformers_['t1'].get_feature_names_out(ohe)) \\\n",
    "        + oe \\\n",
    "        + stdScaler \\\n",
    "        + [c for c in x_train.columns if c not in (ohe + oe + stdScaler)]\n",
    "\n",
    "# convert to DataFrame\n",
    "x_train_df = pd.DataFrame(x_train_transformed, columns=cols)\n",
    "x_test_df = pd.DataFrame(x_test_transformed, columns=cols)\n",
    "\n",
    "x_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35984459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  ---- WHY NO USE OF COLUMNS ----\\n\\nIn the pipeline, we do not need to manually construct `cols` because the ColumnTransformer inside the pipeline handles all transformations internally. \\nThe model receives the transformed array directly, and we never convert it back to a DataFrame for the model to work. \\n`cols` is only needed if you want a DataFrame with proper column names for inspection, analysis, or exporting. \\nFor fitting and predicting with the pipeline, the numeric array output from the transformer is sufficient.\\n\\n_______________________________________________________________________________________________________________________________________________________________\\n\\n\\nso when i use pipeline, whenever i call this pipe.fit(x_train, y_train) or this pipe.predict(x_test), \\ni dont need to manually use encode or scale data using fit_transform. \\n\\nWhenever pipe is called it automatically first scale and encode the x_train columns (which will not be applied to y_train) and \\nafter doing these then it will use logistic regression to find the best possible line.\\n\\nSame will be applied for x_test\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "  ---- WHY NO USE OF COLUMNS ----\n",
    "\n",
    "In the pipeline, we do not need to manually construct `cols` because the ColumnTransformer inside the pipeline handles all transformations internally. \n",
    "The model receives the transformed array directly, and we never convert it back to a DataFrame for the model to work. \n",
    "`cols` is only needed if you want a DataFrame with proper column names for inspection, analysis, or exporting. \n",
    "For fitting and predicting with the pipeline, the numeric array output from the transformer is sufficient.\n",
    "\n",
    "_______________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "so when i use pipeline, whenever i call this pipe.fit(x_train, y_train) or this pipe.predict(x_test), \n",
    "i dont need to manually use encode or scale data using fit_transform. \n",
    "\n",
    "Whenever pipe is called it automatically first scale and encode the x_train columns (which will not be applied to y_train) and \n",
    "after doing these then it will use logistic regression to find the best possible line.\n",
    "\n",
    "Same will be applied for x_test\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
