{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a610c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "import scipy.stats as stats\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd18dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>25.745000</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2</td>\n",
       "      <td>3279.868550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.976978</td>\n",
       "      <td>female</td>\n",
       "      <td>25.744165</td>\n",
       "      <td>yes</td>\n",
       "      <td>southeast</td>\n",
       "      <td>3</td>\n",
       "      <td>21454.494239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>30.030000</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1</td>\n",
       "      <td>1720.353700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>30.676891</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>3</td>\n",
       "      <td>6801.437542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>32.010000</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1</td>\n",
       "      <td>11946.625900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625</th>\n",
       "      <td>48.820767</td>\n",
       "      <td>female</td>\n",
       "      <td>41.426984</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>4</td>\n",
       "      <td>10987.324964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>38.661977</td>\n",
       "      <td>female</td>\n",
       "      <td>26.202557</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>2</td>\n",
       "      <td>11735.844352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>male</td>\n",
       "      <td>40.300000</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>10602.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>48.061207</td>\n",
       "      <td>female</td>\n",
       "      <td>34.930624</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1</td>\n",
       "      <td>8976.140452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>37.598865</td>\n",
       "      <td>female</td>\n",
       "      <td>25.219233</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>3</td>\n",
       "      <td>7027.698968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age     sex        bmi smoker     region  children       charges\n",
       "0     21.000000    male  25.745000     no  northeast         2   3279.868550\n",
       "1     36.976978  female  25.744165    yes  southeast         3  21454.494239\n",
       "2     18.000000    male  30.030000     no  southeast         1   1720.353700\n",
       "3     37.000000    male  30.676891     no  northeast         3   6801.437542\n",
       "4     58.000000    male  32.010000     no  southeast         1  11946.625900\n",
       "...         ...     ...        ...    ...        ...       ...           ...\n",
       "3625  48.820767  female  41.426984     no  northwest         4  10987.324964\n",
       "3626  38.661977  female  26.202557     no  southeast         2  11735.844352\n",
       "3627  56.000000    male  40.300000     no  southwest         0  10602.385000\n",
       "3628  48.061207  female  34.930624     no  southeast         1   8976.140452\n",
       "3629  37.598865  female  25.219233     no  northeast         3   7027.698968\n",
       "\n",
       "[3630 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Medical Insurance Train Data.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efee96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sex  smoker  region       age       bmi  children       charges\n",
      "0  0.0     0.0     0.0 -1.472262 -0.897822 -0.294091   3279.868550\n",
      "1  1.0     1.0     1.0 -0.157215 -0.897976  0.289908  21454.494239\n",
      "2  0.0     0.0     1.0 -1.719189 -0.110219 -0.878090   1720.353700\n",
      "3  0.0     0.0     0.0 -0.155320  0.008683  0.289908   6801.437542\n",
      "4  0.0     0.0     1.0  1.573167  0.253714 -0.878090  11946.625900 \n",
      "\n",
      "\n",
      "CORR WITH ALL THE COLUMNS : \n",
      "                sex    smoker    region       age       bmi  children   charges\n",
      "sex       1.000000 -0.078318  0.053221  0.152745  0.011215 -0.147182 -0.092703\n",
      "smoker   -0.078318  1.000000 -0.091752  0.026564  0.045921 -0.183507  0.777175\n",
      "region    0.053221 -0.091752  1.000000 -0.052556 -0.019890  0.069923 -0.155723\n",
      "age       0.152745  0.026564 -0.052556  1.000000  0.143527 -0.061076  0.299692\n",
      "bmi       0.011215  0.045921 -0.019890  0.143527  1.000000 -0.041996  0.211325\n",
      "children -0.147182 -0.183507  0.069923 -0.061076 -0.041996  1.000000 -0.075089\n",
      "charges  -0.092703  0.777175 -0.155723  0.299692  0.211325 -0.075089  1.000000 \n",
      "\n",
      "\n",
      "CORR ONLY WITH 'charges' : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sex        -0.092703\n",
       "smoker      0.777175\n",
       "region     -0.155723\n",
       "age         0.299692\n",
       "bmi         0.211325\n",
       "children   -0.075089\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['sex', 'smoker', 'region']\n",
    "num = ['age', 'bmi', 'children']\n",
    "\n",
    "trf = ColumnTransformer([\n",
    "    ('trf1', StandardScaler(), num)\n",
    "], remainder='passthrough')\n",
    "\n",
    "oe = OrdinalEncoder(categories=[\n",
    "    ['male', 'female'],      # order for sex\n",
    "    ['no', 'yes'],           # order for smoker\n",
    "    ['northeast', 'southeast', 'northwest', 'southwest']   # order for region\n",
    "])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "MANUALLY DOING ORDINAL ENCODING\n",
    "\n",
    "df['sex'] = df['sex'].map({'female':0, 'male':1})\n",
    "df['smoker'] = df['smoker'].map({'no':0, 'yes':1})\n",
    "df['region'] = df['region'].map({'southwest':0, 'southeast':1, 'northwest':2, 'northeast':3})\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "x = df.iloc[:, :6]\n",
    "y = df.iloc[:, 6:7]\n",
    "\n",
    "\n",
    "x[text] = oe.fit_transform(x[text])\n",
    "x[num] = trf.fit_transform(x[num])\n",
    "\n",
    "x = pd.DataFrame(pd.concat([x[text], x[num], y], axis=1))\n",
    "\n",
    "# more the corr is close to 1 will be highly corelated and imp, and vice-versa for being closer to 0\n",
    "print(x.head(), \"\\n\\n\")\n",
    "print(\"CORR WITH ALL THE COLUMNS : \\n\", x.corr(), \"\\n\\n\")         # this will show correlation of one column with each column\n",
    "\n",
    "print(\"CORR ONLY WITH 'charges' : \")\n",
    "corr_target = x.corr()['charges'].drop('charges')       # this will show correlation of all the columns only with output column ['charges']\n",
    "corr_target     # as we can see in the column, [sex, region, and children] are very less corelated, hence we can remove them and do the dimensionality reduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a809f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex         -9.0\n",
       "smoker      78.0\n",
       "region     -16.0\n",
       "age         30.0\n",
       "bmi         21.0\n",
       "children    -8.0\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(corr_target, 2)*100\n",
    "#  now you can easily see the columns with very low corr with 'charges'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68250a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    Positive correlation (+ve integers) means the feature increases when charges increase.\\n    Negative correlation (-ve integers) means the feature decreases when charges increase.\\n    The sign (+ or -) only shows direction, not importance.\\n    Importance is based on the absolute value of the correlation.\\n\\n    smoker has +78 → strong positive relationship → keep\\n    age has +30 → moderate positive → keep\\n    bmi has +21 → weak positive → optional but usually keep\\n    region has -16 → weak negative → can drop\\n    sex has -9 → very weak negative → drop\\n    children has -8 → very weak negative → drop\\n\\n    General rule:\\n    |corr| < 0.10 → no meaningful relationship → drop\\n    |corr| 0.10-0.30 → weak → optional\\n    |corr| > 0.30 → meaningful → keep\\n\\n\\nINTERPRETATION --\\n\\nFeature      Corr %   Interpretation\\n---------------------------------------------------------------------------\\nsmoker       +78      Smokers have much higher charges.\\nage          +30      Older individuals pay more on average.\\nbmi          +21      Higher BMI tends to increase charges.\\nregion       -16      Region slightly decreases or shifts charges (this means different pay based on different regions).\\nsex          -9       Sex has almost no meaningful effect.\\nchildren     -8       Number of children has minimal impact.\\n\\n\\n\\nTHINGS TO KEEP IN MIND WHILE USING CORR :\\n\\n1. Correlation does NOT imply causation. It only shows association, not the reason behind it.\\n2. Correlation measures only **linear** relationships. If the relationship is non-linear, correlation can be misleading or show near zero.\\n3. Correlation is **sensitive to outliers**. A few extreme values can drastically change the correlation value.\\n4. Correlation requires **numeric data**. If categorical variables are encoded poorly (e.g., ordinal encoding when order doesn't make sense), correlation results can become misleading.\\n5. Correlation evaluates **each feature independently**, not feature interactions. Some features may matter only when combined with others.\\n6. **Multicollinearity** matters. If two features are highly correlated with each other, their individual correlation with the target may be confusing to interpret.\\n7. Scaling does not affect correlation, but **incorrect encoding choices** can change interpretation.\\n\\nGood practice:\\nUse correlation as an initial filter, but always confirm using model-based feature importance or SHAP to understand true influence.\\n\\n\\n\\nWHAT TO DO, WHEN THE DATA IS IN CATEGORICAL TEXT ?? AS ORDINAL ENCODING FOR THESE DATA CAN BE MISLEADING\\n\\n    Correct approach:\\n    1. Numeric   vs   Numeric → Pearson correlation\\n    2. Categorical (input)  vs  Categorical (output) → Cramer's V (or Chi-Square association)\\n    3. Categorical (input)  vs  Numeric (output) → Point-Biserial correlation (or ANOVA)\\n\\n\\n________________________________________________________________________________________________________________________________________________________________________________________________________________\\n\\n\\nWHAT TO DO WHEN THE INPUT IN TEXT OR CATEGORICAL AND OUTPUT IN TEXT \\nWHAT TO DO WHEN THE INPUT IN TEXT OR CATEGORICAL AND OUTPUT IN CATEGORICAL\\n\\nCASE SELECTION FOR CORRELATION / FEATURE-ASSOCIATION ANALYSIS\\n\\n1) When OUTPUT is NUMERIC → Regression-type correlation\\n\\n   a) Numeric input → Numeric output:\\n      Use PEARSON correlation.\\n\\n   b) Binary categorical input → Numeric output:\\n      Use POINT-BISERIAL correlation.\\n\\n   c) Categorical input with more than 2 categories → Numeric output:\\n      Use ANOVA or Kruskal-Wallis instead of correlation.\\n\\n\\n2) When OUTPUT is CATEGORICAL → Classification-type association\\n\\n   a) Numeric input → Categorical output:\\n      Use Logistic Regression feature coefficients or MUTUAL INFORMATION.\\n\\n   b) Categorical input → Categorical output:\\n      Use CRAMER'S V.\\n\\n   c) Mixed numeric + categorical → Categorical output:\\n      Use MUTUAL INFORMATION (most general and safest).\\n\\n\\nSUMMARY TABLE\\n--------------------------------------------------\\nInput vs Output                    | Best Method\\n--------------------------------------------------\\nNumeric → Numeric                  | Pearson Correlation\\nBinary Categorical → Numeric       | Point-Biserial Correlation\\nMulti-Categorical → Numeric        | ANOVA / Kruskal-Wallis\\nNumeric → Categorical              | Logistic Coeff / Mutual Information\\nCategorical → Categorical          | Cramer's V\\nMixed → Categorical                | Mutual Information\\n\\n\\nKEY RULE:\\nDo NOT use Pearson correlation on Ordinal-Encoded categorical variables \\nif the ordering is artificial. The sign and magnitude will be misleading.\\n\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    Positive correlation (+ve integers) means the feature increases when charges increase.\n",
    "    Negative correlation (-ve integers) means the feature decreases when charges increase.\n",
    "    The sign (+ or -) only shows direction, not importance.\n",
    "    Importance is based on the absolute value of the correlation.\n",
    "\n",
    "    smoker has +78 → strong positive relationship → keep\n",
    "    age has +30 → moderate positive → keep\n",
    "    bmi has +21 → weak positive → optional but usually keep\n",
    "    region has -16 → weak negative → can drop\n",
    "    sex has -9 → very weak negative → drop\n",
    "    children has -8 → very weak negative → drop\n",
    "\n",
    "    General rule:\n",
    "    |corr| < 0.10 → no meaningful relationship → drop\n",
    "    |corr| 0.10-0.30 → weak → optional\n",
    "    |corr| > 0.30 → meaningful → keep\n",
    "\n",
    "\n",
    "INTERPRETATION --\n",
    "\n",
    "Feature      Corr %   Interpretation\n",
    "---------------------------------------------------------------------------\n",
    "smoker       +78      Smokers have much higher charges.\n",
    "age          +30      Older individuals pay more on average.\n",
    "bmi          +21      Higher BMI tends to increase charges.\n",
    "region       -16      Region slightly decreases or shifts charges (this means different pay based on different regions).\n",
    "sex          -9       Sex has almost no meaningful effect.\n",
    "children     -8       Number of children has minimal impact.\n",
    "\n",
    "\n",
    "\n",
    "THINGS TO KEEP IN MIND WHILE USING CORR :\n",
    "\n",
    "1. Correlation does NOT imply causation. It only shows association, not the reason behind it.\n",
    "2. Correlation measures only **linear** relationships. If the relationship is non-linear, correlation can be misleading or show near zero.\n",
    "3. Correlation is **sensitive to outliers**. A few extreme values can drastically change the correlation value.\n",
    "4. Correlation requires **numeric data**. If categorical variables are encoded poorly (e.g., ordinal encoding when order doesn't make sense), correlation results can become misleading.\n",
    "5. Correlation evaluates **each feature independently**, not feature interactions. Some features may matter only when combined with others.\n",
    "6. **Multicollinearity** matters. If two features are highly correlated with each other, their individual correlation with the target may be confusing to interpret.\n",
    "7. Scaling does not affect correlation, but **incorrect encoding choices** can change interpretation.\n",
    "\n",
    "Good practice:\n",
    "Use correlation as an initial filter, but always confirm using model-based feature importance or SHAP to understand true influence.\n",
    "\n",
    "\n",
    "\n",
    "WHAT TO DO, WHEN THE DATA IS IN CATEGORICAL TEXT ?? AS ORDINAL ENCODING FOR THESE DATA CAN BE MISLEADING\n",
    "\n",
    "    Correct approach:\n",
    "    1. Numeric   vs   Numeric → Pearson correlation\n",
    "    2. Categorical (input)  vs  Categorical (output) → Cramer's V (or Chi-Square association)\n",
    "    3. Categorical (input)  vs  Numeric (output) → Point-Biserial correlation (or ANOVA)\n",
    "\n",
    "\n",
    "________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "WHAT TO DO WHEN THE INPUT IN TEXT OR CATEGORICAL AND OUTPUT IN TEXT \n",
    "WHAT TO DO WHEN THE INPUT IN TEXT OR CATEGORICAL AND OUTPUT IN CATEGORICAL\n",
    "\n",
    "CASE SELECTION FOR CORRELATION / FEATURE-ASSOCIATION ANALYSIS\n",
    "\n",
    "1) When OUTPUT is NUMERIC → Regression-type correlation\n",
    "\n",
    "   a) Numeric input → Numeric output:\n",
    "      Use PEARSON correlation.\n",
    "\n",
    "   b) Binary categorical input → Numeric output:\n",
    "      Use POINT-BISERIAL correlation.\n",
    "\n",
    "   c) Categorical input with more than 2 categories → Numeric output:\n",
    "      Use ANOVA or Kruskal-Wallis instead of correlation.\n",
    "\n",
    "\n",
    "2) When OUTPUT is CATEGORICAL → Classification-type association\n",
    "\n",
    "   a) Numeric input → Categorical output:\n",
    "      Use Logistic Regression feature coefficients or MUTUAL INFORMATION.\n",
    "\n",
    "   b) Categorical input → Categorical output:\n",
    "      Use CRAMER'S V.\n",
    "\n",
    "   c) Mixed numeric + categorical → Categorical output:\n",
    "      Use MUTUAL INFORMATION (most general and safest).\n",
    "\n",
    "\n",
    "SUMMARY TABLE\n",
    "--------------------------------------------------\n",
    "Input vs Output                    | Best Method\n",
    "--------------------------------------------------\n",
    "Numeric → Numeric                  | Pearson Correlation\n",
    "Binary Categorical → Numeric       | Point-Biserial Correlation\n",
    "Multi-Categorical → Numeric        | ANOVA / Kruskal-Wallis\n",
    "Numeric → Categorical              | Logistic Coeff / Mutual Information\n",
    "Categorical → Categorical          | Cramer's V\n",
    "Mixed → Categorical                | Mutual Information\n",
    "\n",
    "\n",
    "KEY RULE:\n",
    "Do NOT use Pearson correlation on Ordinal-Encoded categorical variables \n",
    "if the ordering is artificial. The sign and magnitude will be misleading.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f47efd",
   "metadata": {},
   "source": [
    "## Other Ways we can use, to find corr without using corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b439d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mudar\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sex         3.802227e-06\n",
       "smoker      3.558967e-07\n",
       "region      1.208884e-05\n",
       "age         1.423491e-05\n",
       "bmi         1.478093e-05\n",
       "children    1.448682e-05\n",
       "charges     9.999403e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x, y)\n",
    "pd.Series(rf.feature_importances_, index=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b22bd905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex         6.229467e-07\n",
       "smoker      4.889768e-08\n",
       "region      2.077781e-06\n",
       "age         3.579176e-06\n",
       "bmi         2.237772e-06\n",
       "children    1.064527e-05\n",
       "charges     2.007804e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Permutation Importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(rf, x, y, n_repeats=5)\n",
    "pd.Series(result.importances_mean, index=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83459984",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# using SHAP Values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshap\u001b[39;00m\n\u001b[32m      3\u001b[39m explainer = shap.TreeExplainer(rf)\n\u001b[32m      4\u001b[39m shap_values = explainer.shap_values(x)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "# using SHAP Values\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(x)\n",
    "shap.summary_plot(shap_values, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8c459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biswa\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sex         0.191223\n",
       "smoker      0.317672\n",
       "region      0.341106\n",
       "age         1.851768\n",
       "bmi         0.541868\n",
       "children    0.623328\n",
       "charges     6.900971\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Mutual Information (MI)\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mi = mutual_info_regression(x, y)\n",
    "pd.Series(mi, index=x.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d4787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\biswa\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sex         3.144864e+01\n",
       "smoker      5.533651e+03\n",
       "region      9.016445e+01\n",
       "age         3.580036e+02\n",
       "bmi         1.695944e+02\n",
       "children    2.057190e+01\n",
       "charges    -8.169530e+18\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANOVA F-score (for continuous target)\n",
    "from sklearn.feature_selection import f_regression\n",
    "f_scores, p_values = f_regression(x, y)\n",
    "pd.Series(f_scores, index=x.columns)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
